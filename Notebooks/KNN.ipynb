{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dde0db3-0ca0-4d17-b869-850ebe7b2673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Test Accuracy: 0.8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.88      0.98      0.92        88\n",
      "         Low       0.75      0.96      0.84       182\n",
      "      Medium       0.86      0.46      0.60       130\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.83      0.80      0.79       400\n",
      "weighted avg       0.81      0.80      0.78       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 86   0   2]\n",
      " [  0 174   8]\n",
      " [ 12  58  60]]\n",
      "\n",
      "Predicted Obesity Risk Category: High\n",
      "\n",
      "Recommended Meals:\n",
      "                                                Descrip  Energy_kcal  \\\n",
      "1633        Leavening agents, baking powder, low-sodium         97.0   \n",
      "826                   Peas, mature seeds, sprouted, raw        124.0   \n",
      "847   Turkey from whole, enhanced, light meat, meat ...        127.0   \n",
      "1662  Turkey, breast, from whole bird, enhanced, mea...        127.0   \n",
      "373   Turkey, wing, from whole bird, enhanced, meat ...        127.0   \n",
      "\n",
      "      Protein_g  Fat_g  Carb_g  \n",
      "1633       0.10   0.40   46.90  \n",
      "826        8.80   0.68   27.11  \n",
      "847       26.97   2.08    0.00  \n",
      "1662      26.97   2.08    0.00  \n",
      "373       26.97   2.08    0.00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import learning_curve, cross_val_score, KFold\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import os\n",
    "import joblib\n",
    "import datetime\n",
    "from sklearn.calibration import calibration_curve\n",
    "import json\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "output_dir = r\"C:\\Users\\trejan\\Desktop\\GNN\\XGB\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Current timestamp for file naming\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Function to save plot\n",
    "def save_plot(fig, filename):\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    fig.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "\n",
    "# Function to save metrics to JSON\n",
    "def save_metrics(metrics_dict, filename):\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(metrics_dict, f, indent=4)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "\n",
    "# Save the trained model\n",
    "def save_model(model, scaler, label_encoders, target_le, filename):\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    model_data = {\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'label_encoders': label_encoders,\n",
    "        'target_encoder': target_le\n",
    "    }\n",
    "    joblib.dump(model_data, filepath)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "\n",
    "# Add these sections right after the k-NN model evaluation in your script\n",
    "\n",
    "# 1. Save the model and associated transformers\n",
    "save_model(knn_model, scaler, label_encoders, target_le, f\"knn_obesity_model_{timestamp}.pkl\")\n",
    "\n",
    "# 2. Calculate and save detailed metrics\n",
    "metrics = {\n",
    "    'accuracy': float(accuracy_score(y_test, y_pred_knn)),\n",
    "    'classification_report': classification_report(y_test, y_pred_knn, target_names=target_le.classes_, output_dict=True)\n",
    "}\n",
    "save_metrics(metrics, f\"model_metrics_{timestamp}.json\")\n",
    "\n",
    "# 3. Generate and save confusion matrix plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred_knn)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=target_le.classes_, \n",
    "            yticklabels=target_le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "save_plot(plt.gcf(), f\"confusion_matrix_{timestamp}.png\")\n",
    "\n",
    "# 4. Generate and save feature importance (for k-NN, use permutation importance)\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm_importance = permutation_importance(knn_model, X_test_scaled, y_test, n_repeats=10, random_state=42)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': perm_importance.importances_mean\n",
    "})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "plt.title('Feature Importance (Permutation-based)')\n",
    "plt.tight_layout()\n",
    "save_plot(plt.gcf(), f\"feature_importance_{timestamp}.png\")\n",
    "\n",
    "# 5. Generate and save learning curves\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    knn_model, X_gen, y_encoded, train_sizes=train_sizes, cv=5, scoring='accuracy')\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', marker='+', markersize=5, label='Validation accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning Curves')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "save_plot(plt.gcf(), f\"learning_curve_{timestamp}.png\")\n",
    "\n",
    "# 6. Generate and save cross-validation scores\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(knn_model, X_gen, y_encoded, cv=cv, scoring='accuracy')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, 6), cv_scores, color='skyblue')\n",
    "plt.axhline(y=cv_scores.mean(), color='red', linestyle='-', label=f'Mean Accuracy: {cv_scores.mean():.4f}')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.title('5-Fold Cross-Validation Scores')\n",
    "plt.xticks(range(1, 6))\n",
    "plt.legend()\n",
    "save_plot(plt.gcf(), f\"cross_validation_scores_{timestamp}.png\")\n",
    "\n",
    "# 7. Generate and save ROC curves (for multi-class, one-vs-rest approach)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Binarize the output for ROC calculation\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_encoded))\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# Fit OneVsRest classifier for ROC calculation\n",
    "ovr_clf = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=11))\n",
    "ovr_clf.fit(X_train_scaled, label_binarize(y_train, classes=np.unique(y_encoded)))\n",
    "y_score = ovr_clf.predict_proba(X_test_scaled)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "plt.figure(figsize=(12, 8))\n",
    "roc_auc = {}\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'ROC curve (class {target_le.classes_[i]}) (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "save_plot(plt.gcf(), f\"roc_curves_{timestamp}.png\")\n",
    "\n",
    "# 8. Generate and save k-value optimization plot (if not already chosen)\n",
    "k_range = list(range(1, 31, 2))\n",
    "k_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_gen, y_encoded, cv=5, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, k_scores, marker='o')\n",
    "plt.xlabel('Value of K')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.title('k-NN: Accuracy for Different Values of k')\n",
    "plt.grid(True)\n",
    "save_plot(plt.gcf(), f\"k_optimization_{timestamp}.png\")\n",
    "\n",
    "# 9. Generate and save detailed distribution of predictions\n",
    "pred_df = pd.DataFrame({\n",
    "    'Actual': target_le.inverse_transform(y_test),\n",
    "    'Predicted': target_le.inverse_transform(y_pred_knn)\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Actual', hue='Predicted', data=pred_df, palette='viridis')\n",
    "plt.title('Distribution of Predictions by Actual Class')\n",
    "plt.xlabel('Actual Class')\n",
    "plt.ylabel('Count')\n",
    "save_plot(plt.gcf(), f\"prediction_distribution_{timestamp}.png\")\n",
    "\n",
    "# 10. Save a summary report\n",
    "summary = {\n",
    "    'model_type': 'KNeighborsClassifier',\n",
    "    'n_neighbors': 11,\n",
    "    'accuracy': float(metrics['accuracy']),\n",
    "    'mean_cv_accuracy': float(cv_scores.mean()),\n",
    "    'std_cv_accuracy': float(cv_scores.std()),\n",
    "    'top_features': feature_importance['Feature'].iloc[:5].tolist(),\n",
    "    'timestamp': timestamp\n",
    "}\n",
    "save_metrics(summary, f\"model_summary_{timestamp}.json\")\n",
    "\n",
    "# Print completion message\n",
    "print(f\"\\nEvaluation complete! All metrics and visualizations saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33edcadb-71a2-4b7e-b211-8b0f91fdf3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Test Accuracy: 0.8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.88      0.98      0.92        88\n",
      "         Low       0.75      0.96      0.84       182\n",
      "      Medium       0.86      0.46      0.60       130\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.83      0.80      0.79       400\n",
      "weighted avg       0.81      0.80      0.78       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 86   0   2]\n",
      " [  0 174   8]\n",
      " [ 12  58  60]]\n",
      "\n",
      "Model and preprocessing artifacts saved to: C:\\Users\\trejan\\Desktop\\GNN\\Saved models\n",
      "\n",
      "Predicted Obesity Risk Category: High\n",
      "\n",
      "Recommended Meals:\n",
      "                                            Descrip  Energy_kcal  Protein_g  \\\n",
      "2088     Nuts, pecans, oil roasted, with salt added        715.0       9.20   \n",
      "1806  Nuts, pecans, oil roasted, without salt added        715.0       9.20   \n",
      "1997     Nuts, pecans, dry roasted, with salt added        710.0       9.50   \n",
      "1079  Nuts, pecans, dry roasted, without salt added        710.0       9.50   \n",
      "2172                                   Nuts, pecans        691.0       9.17   \n",
      "\n",
      "      Fat_g  Carb_g  \n",
      "2088  75.23   13.01  \n",
      "1806  75.23   13.01  \n",
      "1997  74.27   13.55  \n",
      "1079  74.27   13.55  \n",
      "2172  71.97   13.86  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 556, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1038, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1550, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import os\n",
    "import joblib  # Added for model saving\n",
    "\n",
    "# Set environment variables and parallel processing configuration\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '4'\n",
    "\n",
    "#############################\n",
    "# Pipeline 1: k-NN for Obesity Risk Prediction\n",
    "#############################\n",
    "\n",
    "# Load genetic dataset\n",
    "genetic_file_path = r\"C:\\Users\\trejan\\Desktop\\Sem 2\\Machine Learning\\model\\new_genetic_profiles.csv\"\n",
    "genetic_df = pd.read_csv(genetic_file_path)\n",
    "genetic_df.columns = genetic_df.columns.str.strip()\n",
    "genetic_df.fillna(\"None\", inplace=True)\n",
    "\n",
    "# Convert Obesity_Risk_Score into categories\n",
    "genetic_df['Obesity_Risk_Category'] = pd.cut(\n",
    "    genetic_df['Obesity_Risk_Score'],\n",
    "    bins=[0, 0.5, 0.8, 1],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "# Initialize dictionary to store LabelEncoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in [\"Diet_Type\", \"Physical_Activity\"]:\n",
    "    le = LabelEncoder()\n",
    "    genetic_df[col] = le.fit_transform(genetic_df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode gene variant columns\n",
    "variant_columns = [\"MC4R_Variant\", \"PPARG_Variant\", \"FTO_Variant\", \"LEPR_Variant\"]\n",
    "for col in variant_columns:\n",
    "    genetic_df[col] = genetic_df[col].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    genetic_df[col] = le.fit_transform(genetic_df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Define features and target\n",
    "features = [\n",
    "    \"Age\", \"BMI\", \"Physical_Activity\", \"Diet_Type\",\n",
    "    \"MC4R_Present\", \"MC4R_Variant\",\n",
    "    \"PPARG_Present\", \"PPARG_Variant\",\n",
    "    \"FTO_Present\", \"FTO_Variant\",\n",
    "    \"LEPR_Present\", \"LEPR_Variant\"\n",
    "]\n",
    "target = \"Obesity_Risk_Category\"\n",
    "\n",
    "X_gen = genetic_df[features]\n",
    "y_gen = genetic_df[target]\n",
    "\n",
    "# Encode target labels\n",
    "target_le = LabelEncoder()\n",
    "y_encoded = target_le.fit_transform(y_gen)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_gen, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train k-NN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=11)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "print(\"k-NN Test Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn, target_names=target_le.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "# Save model and preprocessing artifacts\n",
    "save_dir = r\"C:\\Users\\trejan\\Desktop\\GNN\\Saved models\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # Create directory if needed\n",
    "\n",
    "joblib.dump(knn_model, os.path.join(save_dir, \"knn_model.pkl\"))\n",
    "joblib.dump(scaler, os.path.join(save_dir, \"scaler.pkl\"))\n",
    "joblib.dump(label_encoders, os.path.join(save_dir, \"label_encoders.pkl\"))\n",
    "joblib.dump(target_le, os.path.join(save_dir, \"target_encoder.pkl\"))\n",
    "\n",
    "print(f\"\\nModel and preprocessing artifacts saved to: {save_dir}\")\n",
    "\n",
    "#############################\n",
    "# Pipeline 2: Meal Recommendation\n",
    "#############################\n",
    "\n",
    "# Load meal dataset\n",
    "meal_file_path = r\"C:\\Users\\trejan\\Desktop\\Sem 2\\Machine Learning\\model\\train.csv\"\n",
    "meal_df = pd.read_csv(meal_file_path)\n",
    "\n",
    "# Preprocess nutritional features\n",
    "nutritional_features = meal_df[['Energy_kcal', 'Protein_g', 'Fat_g', 'Carb_g']]\n",
    "scaler_meal = StandardScaler()\n",
    "nutritional_features_scaled = scaler_meal.fit_transform(nutritional_features)\n",
    "\n",
    "# Cluster meals\n",
    "num_clusters = 10\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "meal_df['Meal_Cluster'] = kmeans.fit_predict(nutritional_features_scaled)\n",
    "\n",
    "# Recommendation function (unchanged)\n",
    "def recommend_meals(user_profile, meal_df, knn_model, target_le, scaler, num_meals=5):\n",
    "    user_profile_df = pd.DataFrame([user_profile])\n",
    "    \n",
    "    for col in [\"Diet_Type\", \"Physical_Activity\"]:\n",
    "        if col in user_profile_df.columns:\n",
    "            le = label_encoders[col]\n",
    "            user_profile_df[col] = le.transform(user_profile_df[col])\n",
    "    for col in variant_columns:\n",
    "        if col in user_profile_df.columns:\n",
    "            le = label_encoders[col]\n",
    "            user_profile_df[col] = le.transform(user_profile_df[col].astype(str))\n",
    "    \n",
    "    missing_cols = set(features) - set(user_profile_df.columns)\n",
    "    for col in missing_cols:\n",
    "        user_profile_df[col] = 0\n",
    "    user_profile_df = user_profile_df[features]\n",
    "    \n",
    "    user_profile_scaled = scaler.transform(user_profile_df)\n",
    "    predicted_category = knn_model.predict(user_profile_scaled)[0]\n",
    "    predicted_label = target_le.inverse_transform([predicted_category])[0]\n",
    "    print(f\"\\nPredicted Obesity Risk Category: {predicted_label}\")\n",
    "    \n",
    "    if predicted_label == 'Low':\n",
    "        preferred_clusters = [0, 1, 2, 3]\n",
    "        sort_by = random.choice(['Protein_g', 'Energy_kcal'])\n",
    "        ascending = random.choice([True, False])\n",
    "    elif predicted_label == 'Medium':\n",
    "        preferred_clusters = [4, 5, 6, 7]\n",
    "        sort_by = random.choice(['Energy_kcal', 'Fat_g'])\n",
    "        ascending = random.choice([True, False])\n",
    "    else:\n",
    "        preferred_clusters = [8, 9, 0, 1]\n",
    "        sort_by = random.choice(['Energy_kcal', 'Carb_g'])\n",
    "        ascending = random.choice([True, False])\n",
    "    \n",
    "    recommended_meals = meal_df[meal_df['Meal_Cluster'].isin(preferred_clusters)]\n",
    "    recommended_meals = recommended_meals.sample(frac=1).reset_index(drop=True)\n",
    "    recommended_meals = recommended_meals.sort_values(by=sort_by, ascending=ascending)\n",
    "    \n",
    "    print(\"\\nRecommended Meals:\")\n",
    "    print(recommended_meals[['Descrip', 'Energy_kcal', 'Protein_g', 'Fat_g', 'Carb_g']].head(num_meals))\n",
    "\n",
    "# Example usage\n",
    "new_profile = {\n",
    "    \"Age\": 35,\n",
    "    \"BMI\": 28.5,\n",
    "    \"Physical_Activity\": \"Low\",\n",
    "    \"Diet_Type\": \"High-Fat\",\n",
    "    \"MC4R_Present\": 0,\n",
    "    \"MC4R_Variant\": \"rs17782313_TT\",\n",
    "    \"PPARG_Present\": 0,\n",
    "    \"PPARG_Variant\": \"rs1801282_CG\",\n",
    "    \"FTO_Present\": 1,\n",
    "    \"FTO_Variant\": \"rs9939609_AT\",\n",
    "    \"LEPR_Present\": 1,\n",
    "    \"LEPR_Variant\": \"rs1137101_AG\"\n",
    "}\n",
    "\n",
    "recommend_meals(new_profile, meal_df, knn_model, target_le, scaler, num_meals=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
