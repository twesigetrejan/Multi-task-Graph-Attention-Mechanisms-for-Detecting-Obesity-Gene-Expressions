{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99d223d-94c7-4f59-84e0-bbc70958d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at C:\\Users\\trejan\\Desktop\\GNN\\Saved models\\LogisticRegression.pkl\n",
      "Logistic Regression Test Accuracy: 0.8075\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.89      0.94      0.92        88\n",
      "         Low       0.75      1.00      0.85       182\n",
      "      Medium       0.92      0.45      0.60       130\n",
      "\n",
      "    accuracy                           0.81       400\n",
      "   macro avg       0.85      0.80      0.79       400\n",
      "weighted avg       0.83      0.81      0.79       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 83   0   5]\n",
      " [  0 182   0]\n",
      " [ 10  62  58]]\n",
      "Metrics table saved to C:\\Users\\trejan\\Desktop\\GNN\\XGB\\metrics_table_logreg.csv\n",
      "ROC curves saved to C:\\Users\\trejan\\Desktop\\GNN\\XGB\\roc_curve_logreg.png\n",
      "Precision-Recall curves saved to C:\\Users\\trejan\\Desktop\\GNN\\XGB\\precision_recall_curve_logreg.png\n",
      "Coefficient plot for class 'High' saved to C:\\Users\\trejan\\Desktop\\GNN\\XGB\\logreg_coefficients_High.png\n",
      "Coefficient plot for class 'Low' saved to C:\\Users\\trejan\\Desktop\\GNN\\XGB\\logreg_coefficients_Low.png\n",
      "Coefficient plot for class 'Medium' saved to C:\\Users\\trejan\\Desktop\\GNN\\XGB\\logreg_coefficients_Medium.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 556, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1038, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1550, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Age\n- BMI\n- Diet_Type\n- FTO_Present\n- FTO_Variant\n- ...\nFeature names seen at fit time, yet now missing:\n- Carb_g\n- Energy_kcal\n- Fat_g\n- Protein_g\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 319\u001b[0m\n\u001b[0;32m    303\u001b[0m new_profile \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m35\u001b[39m,\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBMI\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m28.5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLEPR_Variant\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrs1137101_AG\u001b[39m\u001b[38;5;124m\"\u001b[39m       \u001b[38;5;66;03m# Original string value\u001b[39;00m\n\u001b[0;32m    316\u001b[0m }\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# Recommend meals for the new profile\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m \u001b[43mrecommend_meals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_profile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeal_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogreg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_le\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_meals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 269\u001b[0m, in \u001b[0;36mrecommend_meals\u001b[1;34m(user_profile, meal_df, model, label_encoder, num_meals)\u001b[0m\n\u001b[0;32m    266\u001b[0m user_profile_df \u001b[38;5;241m=\u001b[39m user_profile_df[features]\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# Scale the user profile features\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m user_profile_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_profile_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# Predict the obesity risk category for the user profile\u001b[39;00m\n\u001b[0;32m    272\u001b[0m predicted_category \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(user_profile_scaled)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1062\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1059\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1061\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1062\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     _estimator,\n\u001b[0;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m   2844\u001b[0m ):\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \n\u001b[0;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2919\u001b[0m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Age\n- BMI\n- Diet_Type\n- FTO_Present\n- FTO_Variant\n- ...\nFeature names seen at fit time, yet now missing:\n- Carb_g\n- Energy_kcal\n- Fat_g\n- Protein_g\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Define the model save path\n",
    "model_save_path = r\"C:\\Users\\trejan\\Desktop\\GNN\\Saved models\\LogisticRegression.pkl\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = r\"C:\\Users\\trejan\\Desktop\\GNN\\XGB\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#############################\n",
    "# Pipeline 1: Logistic Regression for Obesity Risk Prediction\n",
    "#############################\n",
    "\n",
    "# Load genetic dataset (assumes comma-delimited)\n",
    "genetic_file_path = r\"C:\\Users\\trejan\\Desktop\\Sem 2\\Machine Learning\\model\\new_genetic_profiles.csv\"\n",
    "genetic_df = pd.read_csv(genetic_file_path)\n",
    "genetic_df.columns = genetic_df.columns.str.strip()\n",
    "genetic_df.fillna(\"None\", inplace=True)\n",
    "\n",
    "# Convert Obesity_Risk_Score into categories (Low, Medium, High)\n",
    "genetic_df['Obesity_Risk_Category'] = pd.cut(\n",
    "    genetic_df['Obesity_Risk_Score'],\n",
    "    bins=[0, 0.5, 0.8, 1],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "# Initialize dictionary to store LabelEncoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode categorical variables (Diet_Type, Physical_Activity)\n",
    "for col in [\"Diet_Type\", \"Physical_Activity\"]:\n",
    "    le = LabelEncoder()\n",
    "    genetic_df[col] = le.fit_transform(genetic_df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode gene variant columns as strings (so that \"None\" is encoded too)\n",
    "variant_columns = [\"MC4R_Variant\", \"PPARG_Variant\", \"FTO_Variant\", \"LEPR_Variant\"]\n",
    "for col in variant_columns:\n",
    "    genetic_df[col] = genetic_df[col].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    genetic_df[col] = le.fit_transform(genetic_df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Define features and target for the genetic model\n",
    "features = [\n",
    "    \"Age\", \"BMI\", \"Physical_Activity\", \"Diet_Type\",\n",
    "    \"MC4R_Present\", \"MC4R_Variant\",\n",
    "    \"PPARG_Present\", \"PPARG_Variant\",\n",
    "    \"FTO_Present\", \"FTO_Variant\",\n",
    "    \"LEPR_Present\", \"LEPR_Variant\"\n",
    "]\n",
    "target = \"Obesity_Risk_Category\"\n",
    "\n",
    "X_gen = genetic_df[features]\n",
    "y_gen = genetic_df[target]\n",
    "\n",
    "# Encode target labels (Low, Medium, High)\n",
    "target_le = LabelEncoder()\n",
    "y_encoded = target_le.fit_transform(y_gen)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_gen, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features (important for Logistic Regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "logreg_model = LogisticRegression(\n",
    "    multi_class='multinomial',  # For multi-class classification\n",
    "    solver='lbfgs',            # Suitable for small datasets\n",
    "    max_iter=1000,             # Increase iterations for convergence\n",
    "    random_state=42\n",
    ")\n",
    "logreg_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "with open(model_save_path, 'wb') as model_file:\n",
    "    pickle.dump(logreg_model, model_file)\n",
    "\n",
    "print(f\"Model saved successfully at {model_save_path}\")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_logreg = logreg_model.predict(X_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_logreg)\n",
    "print(\"Logistic Regression Test Accuracy:\", test_accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, target_names=target_le.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_logreg)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Save metrics as a table\n",
    "classification_report_dict = classification_report(y_test, y_pred_logreg, target_names=target_le.classes_, output_dict=True)\n",
    "report_df = pd.DataFrame(classification_report_dict).transpose()\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Test Accuracy'],\n",
    "    'Value': [test_accuracy]\n",
    "})\n",
    "\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, columns=target_le.classes_, index=target_le.classes_)\n",
    "conf_matrix_df['Metric'] = 'Confusion Matrix'\n",
    "\n",
    "# Combine all metrics into a single DataFrame\n",
    "metrics_table = pd.concat([metrics_df, report_df, conf_matrix_df], axis=0)\n",
    "\n",
    "# Save the metrics table as a CSV file\n",
    "metrics_table_path = os.path.join(output_dir, 'metrics_table_logreg.csv')\n",
    "metrics_table.to_csv(metrics_table_path, index=False)\n",
    "print(f\"Metrics table saved to {metrics_table_path}\")\n",
    "\n",
    "# Plot and save the learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(logreg_model, X_train_scaled, y_train, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training score')\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Cross-validation score')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Learning Curves')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(os.path.join(output_dir, 'learning_curve_logreg.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot and save the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=target_le.classes_, yticklabels=target_le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(os.path.join(output_dir, 'confusion_matrix_logreg.png'))\n",
    "plt.close()\n",
    "\n",
    "#############################################\n",
    "# Additional Evaluation Metrics for Logistic Regression\n",
    "#############################################\n",
    "\n",
    "# Binarize the test labels for ROC and Precision-Recall curves\n",
    "n_classes = len(target_le.classes_)\n",
    "y_test_bin = label_binarize(y_test, classes=list(range(n_classes)))\n",
    "y_score = logreg_model.predict_proba(X_test_scaled)\n",
    "\n",
    "# 1. Plot ROC Curves for each class\n",
    "plt.figure()\n",
    "colors = ['blue', 'red', 'green']\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, color=colors[i], lw=2,\n",
    "             label=f\"ROC curve of class {target_le.classes_[i]} (area = {roc_auc:0.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "roc_curve_path = os.path.join(output_dir, 'roc_curve_logreg.png')\n",
    "plt.savefig(roc_curve_path)\n",
    "plt.close()\n",
    "print(f\"ROC curves saved to {roc_curve_path}\")\n",
    "\n",
    "# 2. Plot Precision-Recall Curves for each class\n",
    "plt.figure()\n",
    "for i in range(n_classes):\n",
    "    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    avg_precision = average_precision_score(y_test_bin[:, i], y_score[:, i])\n",
    "    plt.plot(recall, precision, lw=2,\n",
    "             label=f'PR curve of class {target_le.classes_[i]} (AP = {avg_precision:0.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves')\n",
    "plt.legend(loc=\"upper right\")\n",
    "pr_curve_path = os.path.join(output_dir, 'precision_recall_curve_logreg.png')\n",
    "plt.savefig(pr_curve_path)\n",
    "plt.close()\n",
    "print(f\"Precision-Recall curves saved to {pr_curve_path}\")\n",
    "\n",
    "# 3. Plot Coefficient Bar Charts for each class\n",
    "coefficients = logreg_model.coef_  # Shape: (n_classes, n_features)\n",
    "for i, class_label in enumerate(target_le.classes_):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(range(len(features)), coefficients[i], align='center', color='skyblue')\n",
    "    plt.yticks(range(len(features)), features)\n",
    "    plt.xlabel(\"Coefficient Value\")\n",
    "    plt.title(f\"Logistic Regression Coefficients for Class '{class_label}'\")\n",
    "    plt.tight_layout()\n",
    "    coef_plot_path = os.path.join(output_dir, f'logreg_coefficients_{class_label}.png')\n",
    "    plt.savefig(coef_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Coefficient plot for class '{class_label}' saved to {coef_plot_path}\")\n",
    "\n",
    "#############################\n",
    "# Pipeline 2: Meal Recommendation\n",
    "#############################\n",
    "\n",
    "# Load the meal dataset (assumed to be comma-delimited)\n",
    "meal_file_path = r\"C:\\Users\\trejan\\Desktop\\Sem 2\\Machine Learning\\model\\train.csv\"\n",
    "meal_df = pd.read_csv(meal_file_path)\n",
    "\n",
    "# Preprocess nutritional features; here we assume these columns exist\n",
    "nutritional_features = meal_df[['Energy_kcal', 'Protein_g', 'Fat_g', 'Carb_g']]\n",
    "scaler = StandardScaler()\n",
    "nutritional_features_scaled = scaler.fit_transform(nutritional_features)\n",
    "\n",
    "# Cluster meals using KMeans to create diverse groups (e.g., 10 clusters)\n",
    "num_clusters = 10  # Use 10 clusters for more diversity\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "meal_df['Meal_Cluster'] = kmeans.fit_predict(nutritional_features_scaled)\n",
    "\n",
    "# Function to display meal clusters in a user-friendly format\n",
    "def display_meal_cluster(meals, cluster_name, num_meals=5):\n",
    "    print(f\"\\n=== Recommended Meals for {cluster_name} ===\")\n",
    "    print(f\"Total Meals in Cluster: {len(meals)}\")\n",
    "    \n",
    "    # Display a subset of meals\n",
    "    print(f\"\\nTop {num_meals} Meals:\")\n",
    "    print(f\"{'Meal Description':<50} {'Energy (kcal)':<15} {'Protein (g)':<15} {'Fat (g)':<15} {'Carbs (g)':<15}\")\n",
    "    print(\"-\" * 110)\n",
    "    for _, meal in meals.head(num_meals).iterrows():\n",
    "        print(f\"{meal['Descrip']:<50} {meal['Energy_kcal']:<15} {meal['Protein_g']:<15} {meal['Fat_g']:<15} {meal['Carb_g']:<15}\")\n",
    "    \n",
    "    # Display summary of nutritional values\n",
    "    avg_energy = meals['Energy_kcal'].mean()\n",
    "    avg_protein = meals['Protein_g'].mean()\n",
    "    avg_fat = meals['Fat_g'].mean()\n",
    "    avg_carbs = meals['Carb_g'].mean()\n",
    "    \n",
    "    print(\"\\n=== Nutritional Summary ===\")\n",
    "    print(f\"Average Energy (kcal): {avg_energy:.2f}\")\n",
    "    print(f\"Average Protein (g): {avg_protein:.2f}\")\n",
    "    print(f\"Average Fat (g): {avg_fat:.2f}\")\n",
    "    print(f\"Average Carbs (g): {avg_carbs:.2f}\")\n",
    "\n",
    "# Function to recommend meals dynamically based on user profile\n",
    "def recommend_meals(user_profile, meal_df, model, label_encoder, num_meals=5):\n",
    "    # Convert the user profile to a DataFrame\n",
    "    user_profile_df = pd.DataFrame([user_profile])\n",
    "    \n",
    "    # Encode the categorical features in the user profile using stored encoders\n",
    "    for col in [\"Diet_Type\", \"Physical_Activity\"]:\n",
    "        if col in user_profile_df.columns:\n",
    "            le = label_encoders[col]\n",
    "            user_profile_df[col] = le.transform(user_profile_df[col])\n",
    "    for col in variant_columns:\n",
    "        if col in user_profile_df.columns:\n",
    "            le = label_encoders[col]\n",
    "            user_profile_df[col] = le.transform(user_profile_df[col].astype(str))\n",
    "    \n",
    "    # Ensure the user profile has all required features; add missing ones as 0 if needed\n",
    "    missing_cols = set(features) - set(user_profile_df.columns)\n",
    "    for col in missing_cols:\n",
    "        user_profile_df[col] = 0\n",
    "    user_profile_df = user_profile_df[features]\n",
    "    \n",
    "    # Scale the user profile features\n",
    "    user_profile_scaled = scaler.transform(user_profile_df)\n",
    "    \n",
    "    # Predict the obesity risk category for the user profile\n",
    "    predicted_category = model.predict(user_profile_scaled)[0]\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_category])[0]\n",
    "    print(f\"\\nPredicted Obesity Risk Category: {predicted_label}\")\n",
    "    \n",
    "    # Define cluster preferences based on the predicted risk\n",
    "    if predicted_label == 'Low':\n",
    "        # Low-risk users: Focus on high-protein, balanced meals\n",
    "        preferred_clusters = [0, 1, 2]  # Example clusters\n",
    "        sort_by = 'Protein_g'  # Sort by highest protein\n",
    "    elif predicted_label == 'Medium':\n",
    "        # Medium-risk users: Focus on moderate-calorie, balanced meals\n",
    "        preferred_clusters = [3, 4, 5]  # Example clusters\n",
    "        sort_by = 'Energy_kcal'  # Sort by moderate calories\n",
    "    else:\n",
    "        # High-risk users: Focus on low-calorie, nutrient-dense meals\n",
    "        preferred_clusters = [6, 7, 8, 9]  # Example clusters\n",
    "        sort_by = 'Energy_kcal'  # Sort by lowest calories\n",
    "    \n",
    "    # Recommend meals from the preferred clusters\n",
    "    recommended_meals = meal_df[meal_df['Meal_Cluster'].isin(preferred_clusters)]\n",
    "    \n",
    "    # Sort meals based on the user's risk category\n",
    "    if predicted_label == 'High':\n",
    "        recommended_meals = recommended_meals.sort_values(by=sort_by, ascending=True)  # Low calories\n",
    "    else:\n",
    "        recommended_meals = recommended_meals.sort_values(by=sort_by, ascending=False)  # High protein or moderate calories\n",
    "    \n",
    "    # Display recommended meals in a user-friendly format\n",
    "    display_meal_cluster(recommended_meals, f\"{predicted_label}-Risk\", num_meals)\n",
    "\n",
    "# Example new genetic profile\n",
    "new_profile = {\n",
    "    \"Age\": 35,\n",
    "    \"BMI\": 28.5,\n",
    "    \"Physical_Activity\": \"Low\",      # Original string value (will be encoded)\n",
    "    \"Diet_Type\": \"High-Fat\",           # Original string value (will be encoded)\n",
    "    \"MC4R_Present\": 1,\n",
    "    \"MC4R_Variant\": \"rs17782313_TT\",    # Original string value\n",
    "    \"PPARG_Present\": 1,\n",
    "    \"PPARG_Variant\": \"rs1801282_CG\",    # Original string value\n",
    "    \"FTO_Present\": 1,\n",
    "    \"FTO_Variant\": \"rs9939609_AT\",      # Original string value\n",
    "    \"LEPR_Present\": 1,\n",
    "    \"LEPR_Variant\": \"rs1137101_AG\"       # Original string value\n",
    "}\n",
    "\n",
    "# Recommend meals for the new profile\n",
    "recommend_meals(new_profile, meal_df, logreg_model, target_le, num_meals=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45570fd-3335-4ce8-bba5-404ce5ff33ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.8075\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.89      0.94      0.92        88\n",
      "         Low       0.75      1.00      0.85       182\n",
      "      Medium       0.92      0.45      0.60       130\n",
      "\n",
      "    accuracy                           0.81       400\n",
      "   macro avg       0.85      0.80      0.79       400\n",
      "weighted avg       0.83      0.81      0.79       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 83   0   5]\n",
      " [  0 182   0]\n",
      " [ 10  62  58]]\n",
      "\n",
      "Predicted Obesity Risk Category: Medium\n",
      "\n",
      "Recommended Meals:\n",
      "                                                Descrip  Energy_kcal  \\\n",
      "2314     Egg, whole, dried, stabilized, glucose reduced        615.0   \n",
      "364   Snacks, popcorn, oil-popped, microwave, regula...        583.0   \n",
      "589                                   Egg, whole, dried        605.0   \n",
      "1783          Puff pastry, frozen, ready-to-bake, baked        558.0   \n",
      "2985          Candies, HERSHEY'S POT OF GOLD Almond Bar        577.0   \n",
      "\n",
      "      Protein_g  Fat_g  Carb_g  \n",
      "2314      48.17  43.95    2.38  \n",
      "364        7.29  43.55   45.06  \n",
      "589       48.37  43.04    1.53  \n",
      "1783       7.40  38.50   45.70  \n",
      "2985      12.82  38.46   46.15  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "import random  # For introducing randomness in recommendations\n",
    "import os  # To set environment variables\n",
    "\n",
    "# Suppress joblib warning about physical cores\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '4'\n",
    "\n",
    "#############################\n",
    "# Pipeline 1: Logistic Regression for Obesity Risk Prediction\n",
    "#############################\n",
    "\n",
    "# Load genetic dataset (assumes comma-delimited)\n",
    "genetic_file_path = r\"C:\\Users\\trejan\\Desktop\\Sem 2\\Machine Learning\\model\\new_genetic_profiles.csv\"\n",
    "genetic_df = pd.read_csv(genetic_file_path)\n",
    "genetic_df.columns = genetic_df.columns.str.strip()\n",
    "genetic_df.fillna(\"None\", inplace=True)\n",
    "\n",
    "# Convert Obesity_Risk_Score into categories (Low, Medium, High)\n",
    "genetic_df['Obesity_Risk_Category'] = pd.cut(\n",
    "    genetic_df['Obesity_Risk_Score'],\n",
    "    bins=[0, 0.5, 0.8, 1],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "# Initialize dictionary to store LabelEncoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode categorical variables (Diet_Type, Physical_Activity)\n",
    "for col in [\"Diet_Type\", \"Physical_Activity\"]:\n",
    "    le = LabelEncoder()\n",
    "    genetic_df[col] = le.fit_transform(genetic_df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode gene variant columns as strings (so that \"None\" is encoded too)\n",
    "variant_columns = [\"MC4R_Variant\", \"PPARG_Variant\", \"FTO_Variant\", \"LEPR_Variant\"]\n",
    "for col in variant_columns:\n",
    "    genetic_df[col] = genetic_df[col].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    genetic_df[col] = le.fit_transform(genetic_df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Define features and target for the genetic model\n",
    "features = [\n",
    "    \"Age\", \"BMI\", \"Physical_Activity\", \"Diet_Type\",\n",
    "    \"MC4R_Present\", \"MC4R_Variant\",\n",
    "    \"PPARG_Present\", \"PPARG_Variant\",\n",
    "    \"FTO_Present\", \"FTO_Variant\",\n",
    "    \"LEPR_Present\", \"LEPR_Variant\"\n",
    "]\n",
    "target = \"Obesity_Risk_Category\"\n",
    "\n",
    "X_gen = genetic_df[features]\n",
    "y_gen = genetic_df[target]\n",
    "\n",
    "# Encode target labels (Low, Medium, High)\n",
    "target_le = LabelEncoder()\n",
    "y_encoded = target_le.fit_transform(y_gen)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_gen, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features (important for Logistic Regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "logreg_model = LogisticRegression(\n",
    "    solver='lbfgs',            # Suitable for small datasets\n",
    "    max_iter=1000,             # Increase iterations for convergence\n",
    "    random_state=42\n",
    ")\n",
    "logreg_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_logreg = logreg_model.predict(X_test_scaled)\n",
    "print(\"Logistic Regression Test Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, target_names=target_le.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_logreg))\n",
    "\n",
    "#############################\n",
    "# Pipeline 2: Meal Recommendation (Same as Before)\n",
    "#############################\n",
    "\n",
    "# Load the meal dataset (assumed to be comma-delimited)\n",
    "meal_file_path = r\"C:\\Users\\trejan\\Desktop\\Sem 2\\Machine Learning\\model\\train.csv\"\n",
    "meal_df = pd.read_csv(meal_file_path)\n",
    "\n",
    "# Preprocess nutritional features; these columns should exist in your meal dataset\n",
    "nutritional_features = meal_df[['Energy_kcal', 'Protein_g', 'Fat_g', 'Carb_g']]\n",
    "scaler_meal = StandardScaler()\n",
    "nutritional_features_scaled = scaler_meal.fit_transform(nutritional_features)\n",
    "\n",
    "# Cluster meals using KMeans (e.g., 10 clusters)\n",
    "num_clusters = 10\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "meal_df['Meal_Cluster'] = kmeans.fit_predict(nutritional_features_scaled)\n",
    "\n",
    "# Define a meal recommendation function that uses the predicted obesity risk category\n",
    "def recommend_meals(user_profile, meal_df, logreg_model, target_le, scaler, num_meals=5):\n",
    "    \"\"\"\n",
    "    user_profile: dict with genetic feature values (original, unencoded)\n",
    "    logreg_model: trained logistic regression model\n",
    "    target_le: LabelEncoder for the target risk category\n",
    "    scaler: StandardScaler fitted on genetic features\n",
    "    \"\"\"\n",
    "    # Convert user_profile into a DataFrame\n",
    "    user_profile_df = pd.DataFrame([user_profile])\n",
    "    \n",
    "    # Encode categorical features using stored encoders\n",
    "    for col in [\"Diet_Type\", \"Physical_Activity\"]:\n",
    "        if col in user_profile_df.columns:\n",
    "            le = label_encoders[col]\n",
    "            user_profile_df[col] = le.transform(user_profile_df[col])\n",
    "    for col in variant_columns:\n",
    "        if col in user_profile_df.columns:\n",
    "            le = label_encoders[col]\n",
    "            user_profile_df[col] = le.transform(user_profile_df[col].astype(str))\n",
    "    \n",
    "    # Ensure the user profile contains all required features; fill missing with 0\n",
    "    missing_cols = set(features) - set(user_profile_df.columns)\n",
    "    for col in missing_cols:\n",
    "        user_profile_df[col] = 0\n",
    "    user_profile_df = user_profile_df[features]\n",
    "    \n",
    "    # Scale the user profile using the same scaler as training\n",
    "    user_profile_scaled = scaler.transform(user_profile_df)\n",
    "    \n",
    "    # Predict obesity risk using the logistic regression model\n",
    "    predicted_category = logreg_model.predict(user_profile_scaled)[0]\n",
    "    predicted_label = target_le.inverse_transform([predicted_category])[0]\n",
    "    print(f\"\\nPredicted Obesity Risk Category: {predicted_label}\")\n",
    "    \n",
    "    # Define cluster preferences based on predicted risk (example logic)\n",
    "    if predicted_label == 'Low':\n",
    "        preferred_clusters = [0, 1, 2, 3]  # Broaden the cluster selection\n",
    "        sort_by = random.choice(['Protein_g', 'Energy_kcal'])  # Randomize sorting\n",
    "        ascending = random.choice([True, False])  # Randomize order\n",
    "    elif predicted_label == 'Medium':\n",
    "        preferred_clusters = [4, 5, 6, 7]  # Broaden the cluster selection\n",
    "        sort_by = random.choice(['Energy_kcal', 'Fat_g'])  # Randomize sorting\n",
    "        ascending = random.choice([True, False])  # Randomize order\n",
    "    else:\n",
    "        preferred_clusters = [8, 9, 0, 1]  # Broaden the cluster selection\n",
    "        sort_by = random.choice(['Energy_kcal', 'Carb_g'])  # Randomize sorting\n",
    "        ascending = random.choice([True, False])  # Randomize order\n",
    "    \n",
    "    # Filter and sort meals from the preferred clusters\n",
    "    recommended_meals = meal_df[meal_df['Meal_Cluster'].isin(preferred_clusters)]\n",
    "    recommended_meals = recommended_meals.sample(frac=1).reset_index(drop=True)  # Shuffle the meals\n",
    "    recommended_meals = recommended_meals.sort_values(by=sort_by, ascending=ascending)\n",
    "    \n",
    "    print(\"\\nRecommended Meals:\")\n",
    "    print(recommended_meals[['Descrip', 'Energy_kcal', 'Protein_g', 'Fat_g', 'Carb_g']].head(num_meals))\n",
    "\n",
    "# Example new genetic profile for meal recommendation (using original, unencoded values)\n",
    "new_profile = {\n",
    "    \"Age\": 35,\n",
    "    \"BMI\": 28.5,\n",
    "    \"Physical_Activity\": \"Low\",      # Original string (will be encoded)\n",
    "    \"Diet_Type\": \"High-Fat\",           # Original string (will be encoded)\n",
    "    \"MC4R_Present\": 1,\n",
    "    \"MC4R_Variant\": \"rs17782313_TT\",\n",
    "    \"PPARG_Present\": 0,\n",
    "    \"PPARG_Variant\": \"rs1801282_CG\",\n",
    "    \"FTO_Present\": 1,\n",
    "    \"FTO_Variant\": \"rs9939609_AT\",\n",
    "    \"LEPR_Present\": 0,\n",
    "    \"LEPR_Variant\": \"rs1137101_AG\"\n",
    "}\n",
    "\n",
    "# Get meal recommendations using the logistic regression model\n",
    "recommend_meals(new_profile, meal_df, logreg_model, target_le, scaler, num_meals=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
