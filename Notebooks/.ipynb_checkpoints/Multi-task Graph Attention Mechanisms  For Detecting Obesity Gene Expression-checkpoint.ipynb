{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d98bd4-7a4d-4859-8af3-1b4db4b091ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch Geometric imports\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#############################\n",
    "# Data Preprocessing\n",
    "#############################\n",
    "\n",
    "# Load genetic profiles data\n",
    "genetic_file_path = r\"C:\\Users\\trejan\\Desktop\\Sem 2\\Machine Learning\\model\\new_genetic_profiles.csv\"\n",
    "genetic_df = pd.read_csv(genetic_file_path)\n",
    "genetic_df.columns = genetic_df.columns.str.strip()\n",
    "genetic_df.fillna(\"None\", inplace=True)\n",
    "\n",
    "# Create obesity risk category from Obesity_Risk_Score\n",
    "genetic_df['Obesity_Risk_Category'] = pd.cut(\n",
    "    genetic_df['Obesity_Risk_Score'],\n",
    "    bins=[0, 0.5, 0.8, 1],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "# Create BMI category using cut (simulate gene expression analysis via gene variants)\n",
    "genetic_df['BMI_Category'] = pd.cut(\n",
    "    genetic_df['BMI'],\n",
    "    bins=[0, 18.5, 24.9, 29.9, np.inf],\n",
    "    labels=['Underweight', 'Normal', 'Overweight', 'Obese']\n",
    ")\n",
    "\n",
    "# Encode categorical non-gene features\n",
    "label_encoders = {}\n",
    "for col in [\"Diet_Type\", \"Physical_Activity\"]:\n",
    "    le = LabelEncoder()\n",
    "    genetic_df[col] = le.fit_transform(genetic_df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode gene variant columns (simulate gene expression values by encoding variant info)\n",
    "variant_columns = [\"MC4R_Variant\", \"PPARG_Variant\", \"FTO_Variant\", \"LEPR_Variant\"]\n",
    "for col in variant_columns:\n",
    "    genetic_df[col] = genetic_df[col].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    genetic_df[col] = le.fit_transform(genetic_df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Define structured features and gene features\n",
    "structured_features = [\"Age\", \"BMI\", \"Physical_Activity\", \"Diet_Type\"]\n",
    "# For gene branch, for each gene we take two features: presence and variant\n",
    "gene_list = [\"MC4R\", \"PPARG\", \"FTO\", \"LEPR\"]\n",
    "gene_feature_cols = []\n",
    "for gene in gene_list:\n",
    "    gene_feature_cols.append(f\"{gene}_Present\")\n",
    "    gene_feature_cols.append(f\"{gene}_Variant\")\n",
    "\n",
    "# Combine into overall features if needed (here, structured features are used separately)\n",
    "X_structured = genetic_df[structured_features].copy()\n",
    "X_gene = genetic_df[gene_feature_cols].copy()\n",
    "\n",
    "# Encode targets\n",
    "target_le_risk = LabelEncoder()\n",
    "y_risk = target_le_risk.fit_transform(genetic_df['Obesity_Risk_Category'])\n",
    "target_le_bmi = LabelEncoder()\n",
    "y_bmi = target_le_bmi.fit_transform(genetic_df['BMI_Category'])\n",
    "\n",
    "#############################\n",
    "# Scale structured features\n",
    "#############################\n",
    "scaler = StandardScaler()\n",
    "X_structured_scaled = scaler.fit_transform(X_structured)\n",
    "\n",
    "#############################\n",
    "# Train-test split indices\n",
    "#############################\n",
    "train_idx, test_idx = train_test_split(np.arange(len(genetic_df)), test_size=0.2, random_state=42)\n",
    "\n",
    "#############################\n",
    "# Create a PyTorch Geometric Dataset\n",
    "#############################\n",
    "\n",
    "class GeneticDataset(InMemoryDataset):\n",
    "    def __init__(self, structured_data, gene_data, y_risk, y_bmi, indices, transform=None):\n",
    "        self.structured_data = structured_data[indices]\n",
    "        self.gene_data = gene_data.iloc[indices].reset_index(drop=True)\n",
    "        self.y_risk = y_risk[indices]\n",
    "        self.y_bmi = y_bmi[indices]\n",
    "        super(GeneticDataset, self).__init__('.', transform, None, None)\n",
    "        self.data, self.slices = self.process_data()\n",
    "    \n",
    "    def process_data(self):\n",
    "        data_list = []\n",
    "        for i in range(len(self.structured_data)):\n",
    "            # Structured data: vector of features (already scaled)\n",
    "            struct_feat = torch.tensor(self.structured_data[i], dtype=torch.float)\n",
    "            \n",
    "            # Build gene graph for the individual\n",
    "            # We have 4 genes, each with 2 features: [Present, Variant]\n",
    "            gene_feats = self.gene_data.iloc[i].values.astype(np.float32).reshape(len(gene_list), 2)\n",
    "            x_gene = torch.tensor(gene_feats, dtype=torch.float)\n",
    "            \n",
    "            # Define edges for the gene graph.\n",
    "            # Here we assume a fully connected graph (excluding self-loops)\n",
    "            num_genes = x_gene.shape[0]\n",
    "            edge_index = []\n",
    "            for src in range(num_genes):\n",
    "                for dst in range(num_genes):\n",
    "                    if src != dst:\n",
    "                        edge_index.append([src, dst])\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "            \n",
    "            # Create a Data object for the gene branch\n",
    "            gene_data_obj = Data(x=x_gene, edge_index=edge_index)\n",
    "            \n",
    "            # Combine targets into one Data object (weâ€™ll keep structured data separate)\n",
    "            data_obj = Data(struct_feat=struct_feat, gene_data=gene_data_obj,\n",
    "                            y_risk=torch.tensor(self.y_risk[i], dtype=torch.long),\n",
    "                            y_bmi=torch.tensor(self.y_bmi[i], dtype=torch.long))\n",
    "            data_list.append(data_obj)\n",
    "        return self.collate(data_list)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        return super(GeneticDataset, self).get(idx)\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = GeneticDataset(X_structured_scaled, X_gene, y_risk, y_bmi, train_idx)\n",
    "test_dataset = GeneticDataset(X_structured_scaled, X_gene, y_risk, y_bmi, test_idx)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "#############################\n",
    "# Define the Integrated Model\n",
    "#############################\n",
    "class IntegratedModel(nn.Module):\n",
    "    def __init__(self, structured_input_dim, struct_hidden_dim, \n",
    "                 gat_in_dim, gat_hidden_dim, gat_out_dim,\n",
    "                 combined_hidden_dim, risk_out_dim, bmi_out_dim):\n",
    "        super(IntegratedModel, self).__init__()\n",
    "        # Structured branch\n",
    "        self.fc_struct1 = nn.Linear(structured_input_dim, struct_hidden_dim)\n",
    "        self.fc_struct2 = nn.Linear(struct_hidden_dim, struct_hidden_dim)\n",
    "        \n",
    "        # Graph branch (for gene data)\n",
    "        # Using one GAT layer; note: each individual graph has 4 nodes, each with gat_in_dim features\n",
    "        self.gat_conv = GATConv(gat_in_dim, gat_hidden_dim, heads=2, concat=True)\n",
    "        # Readout: global mean pooling will be applied later\n",
    "        \n",
    "        # Combined branch\n",
    "        # We'll concatenate the structured branch output with the gene branch readout\n",
    "        self.fc_comb1 = nn.Linear(struct_hidden_dim + gat_hidden_dim * 2, combined_hidden_dim)\n",
    "        self.fc_comb2 = nn.Linear(combined_hidden_dim, combined_hidden_dim)\n",
    "        \n",
    "        # Multi-task heads\n",
    "        self.fc_risk = nn.Linear(combined_hidden_dim, risk_out_dim)  # e.g., 3 classes\n",
    "        self.fc_bmi = nn.Linear(combined_hidden_dim, bmi_out_dim)    # e.g., 4 classes\n",
    "\n",
    "    def forward(self, struct_feat, gene_data, batch):\n",
    "        # Process structured branch\n",
    "        x_struct = F.relu(self.fc_struct1(struct_feat))\n",
    "        x_struct = F.relu(self.fc_struct2(x_struct))\n",
    "        \n",
    "        # Process graph branch with GAT\n",
    "        # gene_data.x: [total_nodes, gat_in_dim], gene_data.edge_index: graph connectivity\n",
    "        x_gene = self.gat_conv(gene_data.x, gene_data.edge_index)\n",
    "        x_gene = F.elu(x_gene)\n",
    "        # Perform global mean pooling over nodes in each graph using the provided batch vector\n",
    "        x_gene = global_mean_pool(x_gene, batch)\n",
    "        \n",
    "        # Combine the two branches\n",
    "        combined = torch.cat([x_struct, x_gene], dim=1)\n",
    "        combined = F.relu(self.fc_comb1(combined))\n",
    "        combined = F.relu(self.fc_comb2(combined))\n",
    "        \n",
    "        # Two task outputs\n",
    "        out_risk = self.fc_risk(combined)\n",
    "        out_bmi = self.fc_bmi(combined)\n",
    "        return out_risk, out_bmi\n",
    "\n",
    "# Define model hyperparameters\n",
    "structured_input_dim = X_structured_scaled.shape[1]    # e.g., 4 features: Age, BMI, Physical_Activity, Diet_Type\n",
    "struct_hidden_dim = 32\n",
    "gat_in_dim = 2   # each gene node: [Present, Variant]\n",
    "gat_hidden_dim = 8\n",
    "gat_out_dim = 16  # not used directly as we use heads concat\n",
    "combined_hidden_dim = 32\n",
    "risk_out_dim = 3   # Obesity Risk: Low, Medium, High\n",
    "bmi_out_dim = 4    # BMI: Underweight, Normal, Overweight, Obese\n",
    "\n",
    "model = IntegratedModel(structured_input_dim, struct_hidden_dim,\n",
    "                        gat_in_dim, gat_hidden_dim, gat_out_dim,\n",
    "                        combined_hidden_dim, risk_out_dim, bmi_out_dim)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "#############################\n",
    "# Training Setup\n",
    "#############################\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        # batch.struct_feat: [batch_size, structured_input_dim]\n",
    "        struct_feat = batch.struct_feat.to(device)\n",
    "        # For gene branch, batch.gene_data is a Data object with x and edge_index.\n",
    "        # When batching graphs, torch_geometric automatically provides a 'batch' vector.\n",
    "        gene_data = batch.gene_data.to(device)\n",
    "        batch_vector = batch.batch.to(device)  # batch vector for global pooling\n",
    "        \n",
    "        out_risk, out_bmi = model(struct_feat, gene_data, batch_vector)\n",
    "        loss_risk = criterion(out_risk, batch.y_risk.to(device))\n",
    "        loss_bmi = criterion(out_bmi, batch.y_bmi.to(device))\n",
    "        loss = loss_risk + loss_bmi\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def test_epoch(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_risk = 0\n",
    "    correct_bmi = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            struct_feat = batch.struct_feat.to(device)\n",
    "            gene_data = batch.gene_data.to(device)\n",
    "            batch_vector = batch.batch.to(device)\n",
    "            out_risk, out_bmi = model(struct_feat, gene_data, batch_vector)\n",
    "            loss_risk = criterion(out_risk, batch.y_risk.to(device))\n",
    "            loss_bmi = criterion(out_bmi, batch.y_bmi.to(device))\n",
    "            loss = loss_risk + loss_bmi\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "            \n",
    "            pred_risk = out_risk.argmax(dim=1)\n",
    "            pred_bmi = out_bmi.argmax(dim=1)\n",
    "            correct_risk += (pred_risk == batch.y_risk.to(device)).sum().item()\n",
    "            correct_bmi += (pred_bmi == batch.y_bmi.to(device)).sum().item()\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc_risk = correct_risk / len(loader.dataset)\n",
    "    acc_bmi = correct_bmi / len(loader.dataset)\n",
    "    return avg_loss, acc_risk, acc_bmi\n",
    "\n",
    "#############################\n",
    "# Training Loop\n",
    "#############################\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader)\n",
    "    test_loss, test_acc_risk, test_acc_bmi = test_epoch(model, test_loader)\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch}: Train Loss {train_loss:.4f} | Test Loss {test_loss:.4f} | \"\n",
    "              f\"Risk Acc {test_acc_risk:.4f} | BMI Acc {test_acc_bmi:.4f}\")\n",
    "\n",
    "#############################\n",
    "# Save the Integrated Model and Artifacts\n",
    "#############################\n",
    "save_dir = r\"C:\\Users\\trejan\\Desktop\\GNN\\Saved models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(save_dir, \"integrated_model.pt\"))\n",
    "\n",
    "with open(os.path.join(save_dir, \"label_encoders.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "with open(os.path.join(save_dir, \"target_encoders.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({'risk': target_le_risk, 'bmi': target_le_bmi}, f)\n",
    "with open(os.path.join(save_dir, \"scaler.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Integrated model and preprocessing artifacts saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f676d-ecfe-4674-adea-fd97cb69a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch Geometric imports\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#############################\n",
    "# Data Preprocessing\n",
    "#############################\n",
    "\n",
    "# Load genetic profiles data\n",
    "genetic_file_path = r\"C:\\Users\\trejan\\Desktop\\Sem 2\\Machine Learning\\model\\new_genetic_profiles.csv\"\n",
    "genetic_df = pd.read_csv(genetic_file_path)\n",
    "genetic_df.columns = genetic_df.columns.str.strip()\n",
    "genetic_df.fillna(\"None\", inplace=True)\n",
    "\n",
    "# Create obesity risk category from Obesity_Risk_Score\n",
    "genetic_df['Obesity_Risk_Category'] = pd.cut(\n",
    "    genetic_df['Obesity_Risk_Score'],\n",
    "    bins=[0, 0.5, 0.8, 1],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "# Create BMI category using cut (simulate gene expression analysis via gene variants)\n",
    "genetic_df['BMI_Category'] = pd.cut(\n",
    "    genetic_df['BMI'],\n",
    "    bins=[0, 18.5, 24.9, 29.9, np.inf],\n",
    "    labels=['Underweight', 'Normal', 'Overweight', 'Obese']\n",
    ")\n",
    "\n",
    "# Encode categorical non-gene features\n",
    "label_encoders = {}\n",
    "for col in [\"Diet_Type\", \"Physical_Activity\"]:\n",
    "    le = LabelEncoder()\n",
    "    genetic_df[col] = le.fit_transform(genetic_df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode gene variant columns (simulate gene expression values by encoding variant info)\n",
    "variant_columns = [\"MC4R_Variant\", \"PPARG_Variant\", \"FTO_Variant\", \"LEPR_Variant\"]\n",
    "for col in variant_columns:\n",
    "    genetic_df[col] = genetic_df[col].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    genetic_df[col] = le.fit_transform(genetic_df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Define structured features and gene features\n",
    "structured_features = [\"Age\", \"BMI\", \"Physical_Activity\", \"Diet_Type\"]\n",
    "# For gene branch, for each gene we take two features: presence and variant\n",
    "gene_list = [\"MC4R\", \"PPARG\", \"FTO\", \"LEPR\"]\n",
    "gene_feature_cols = []\n",
    "for gene in gene_list:\n",
    "    gene_feature_cols.append(f\"{gene}_Present\")\n",
    "    gene_feature_cols.append(f\"{gene}_Variant\")\n",
    "\n",
    "# Combine into overall features if needed (here, structured features are used separately)\n",
    "X_structured = genetic_df[structured_features].copy()\n",
    "X_gene = genetic_df[gene_feature_cols].copy()\n",
    "\n",
    "# Encode targets\n",
    "target_le_risk = LabelEncoder()\n",
    "y_risk = target_le_risk.fit_transform(genetic_df['Obesity_Risk_Category'])\n",
    "target_le_bmi = LabelEncoder()\n",
    "y_bmi = target_le_bmi.fit_transform(genetic_df['BMI_Category'])\n",
    "\n",
    "#############################\n",
    "# Scale structured features\n",
    "#############################\n",
    "scaler = StandardScaler()\n",
    "X_structured_scaled = scaler.fit_transform(X_structured)\n",
    "\n",
    "#############################\n",
    "# Train-test split indices\n",
    "#############################\n",
    "train_idx, test_idx = train_test_split(np.arange(len(genetic_df)), test_size=0.2, random_state=42)\n",
    "\n",
    "#############################\n",
    "# Create a PyTorch Geometric Dataset\n",
    "#############################\n",
    "\n",
    "class GeneticDataset(InMemoryDataset):\n",
    "    def __init__(self, structured_data, gene_data, y_risk, y_bmi, indices, transform=None):\n",
    "        self.structured_data = structured_data[indices]\n",
    "        self.gene_data = gene_data.iloc[indices].reset_index(drop=True)\n",
    "        self.y_risk = y_risk[indices]\n",
    "        self.y_bmi = y_bmi[indices]\n",
    "        super(GeneticDataset, self).__init__('.', transform, None, None)\n",
    "        self.data, self.slices = self.process_data()\n",
    "    \n",
    "    def process_data(self):\n",
    "        data_list = []\n",
    "        for i in range(len(self.structured_data)):\n",
    "            # Structured data: vector of features (already scaled)\n",
    "            struct_feat = torch.tensor(self.structured_data[i], dtype=torch.float)\n",
    "            \n",
    "            # Build gene graph for the individual\n",
    "            # We have 4 genes, each with 2 features: [Present, Variant]\n",
    "            gene_feats = self.gene_data.iloc[i].values.astype(np.float32).reshape(len(gene_list), 2)\n",
    "            x_gene = torch.tensor(gene_feats, dtype=torch.float)\n",
    "            \n",
    "            # Define edges for the gene graph.\n",
    "            # Here we assume a fully connected graph (excluding self-loops)\n",
    "            num_genes = x_gene.shape[0]\n",
    "            edge_index = []\n",
    "            for src in range(num_genes):\n",
    "                for dst in range(num_genes):\n",
    "                    if src != dst:\n",
    "                        edge_index.append([src, dst])\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "            \n",
    "            # Create a Data object for the gene branch\n",
    "            gene_data_obj = Data(x=x_gene, edge_index=edge_index)\n",
    "            \n",
    "            # Combine targets into one Data object (weâ€™ll keep structured data separate)\n",
    "            data_obj = Data(struct_feat=struct_feat, gene_data=gene_data_obj,\n",
    "                            y_risk=torch.tensor(self.y_risk[i], dtype=torch.long),\n",
    "                            y_bmi=torch.tensor(self.y_bmi[i], dtype=torch.long))\n",
    "            data_list.append(data_obj)\n",
    "        return self.collate(data_list)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        return super(GeneticDataset, self).get(idx)\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = GeneticDataset(X_structured_scaled, X_gene, y_risk, y_bmi, train_idx)\n",
    "test_dataset = GeneticDataset(X_structured_scaled, X_gene, y_risk, y_bmi, test_idx)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "#############################\n",
    "# Define the Integrated Model\n",
    "#############################\n",
    "class IntegratedModel(nn.Module):\n",
    "    def __init__(self, structured_input_dim, struct_hidden_dim, \n",
    "                 gat_in_dim, gat_hidden_dim, gat_out_dim,\n",
    "                 combined_hidden_dim, risk_out_dim, bmi_out_dim):\n",
    "        super(IntegratedModel, self).__init__()\n",
    "        # Structured branch\n",
    "        self.fc_struct1 = nn.Linear(structured_input_dim, struct_hidden_dim)\n",
    "        self.fc_struct2 = nn.Linear(struct_hidden_dim, struct_hidden_dim)\n",
    "        \n",
    "        # Graph branch (for gene data)\n",
    "        # Using one GAT layer; note: each individual graph has 4 nodes, each with gat_in_dim features\n",
    "        self.gat_conv = GATConv(gat_in_dim, gat_hidden_dim, heads=2, concat=True)\n",
    "        # Readout: global mean pooling will be applied later\n",
    "        \n",
    "        # Combined branch\n",
    "        # We'll concatenate the structured branch output with the gene branch readout\n",
    "        self.fc_comb1 = nn.Linear(struct_hidden_dim + gat_hidden_dim * 2, combined_hidden_dim)\n",
    "        self.fc_comb2 = nn.Linear(combined_hidden_dim, combined_hidden_dim)\n",
    "        \n",
    "        # Multi-task heads\n",
    "        self.fc_risk = nn.Linear(combined_hidden_dim, risk_out_dim)  # e.g., 3 classes\n",
    "        self.fc_bmi = nn.Linear(combined_hidden_dim, bmi_out_dim)    # e.g., 4 classes\n",
    "\n",
    "    def forward(self, struct_feat, gene_data, batch):\n",
    "        # Process structured branch\n",
    "        x_struct = F.relu(self.fc_struct1(struct_feat))\n",
    "        x_struct = F.relu(self.fc_struct2(x_struct))\n",
    "        \n",
    "        # Process graph branch with GAT\n",
    "        # gene_data.x: [total_nodes, gat_in_dim], gene_data.edge_index: graph connectivity\n",
    "        x_gene = self.gat_conv(gene_data.x, gene_data.edge_index)\n",
    "        x_gene = F.elu(x_gene)\n",
    "        # Perform global mean pooling over nodes in each graph using the provided batch vector\n",
    "        x_gene = global_mean_pool(x_gene, batch)\n",
    "        \n",
    "        # Combine the two branches\n",
    "        combined = torch.cat([x_struct, x_gene], dim=1)\n",
    "        combined = F.relu(self.fc_comb1(combined))\n",
    "        combined = F.relu(self.fc_comb2(combined))\n",
    "        \n",
    "        # Two task outputs\n",
    "        out_risk = self.fc_risk(combined)\n",
    "        out_bmi = self.fc_bmi(combined)\n",
    "        return out_risk, out_bmi\n",
    "\n",
    "# Define model hyperparameters\n",
    "structured_input_dim = X_structured_scaled.shape[1]    # e.g., 4 features: Age, BMI, Physical_Activity, Diet_Type\n",
    "struct_hidden_dim = 32\n",
    "gat_in_dim = 2   # each gene node: [Present, Variant]\n",
    "gat_hidden_dim = 8\n",
    "gat_out_dim = 16  # not used directly as we use heads concat\n",
    "combined_hidden_dim = 32\n",
    "risk_out_dim = 3   # Obesity Risk: Low, Medium, High\n",
    "bmi_out_dim = 4    # BMI: Underweight, Normal, Overweight, Obese\n",
    "\n",
    "model = IntegratedModel(structured_input_dim, struct_hidden_dim,\n",
    "                        gat_in_dim, gat_hidden_dim, gat_out_dim,\n",
    "                        combined_hidden_dim, risk_out_dim, bmi_out_dim)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "#############################\n",
    "# Training Setup\n",
    "#############################\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        # batch.struct_feat: [batch_size, structured_input_dim]\n",
    "        struct_feat = batch.struct_feat.to(device)\n",
    "        # For gene branch, batch.gene_data is a Data object with x and edge_index.\n",
    "        # When batching graphs, torch_geometric automatically provides a 'batch' vector.\n",
    "        gene_data = batch.gene_data.to(device)\n",
    "        batch_vector = batch.batch.to(device)  # batch vector for global pooling\n",
    "        \n",
    "        out_risk, out_bmi = model(struct_feat, gene_data, batch_vector)\n",
    "        loss_risk = criterion(out_risk, batch.y_risk.to(device))\n",
    "        loss_bmi = criterion(out_bmi, batch.y_bmi.to(device))\n",
    "        loss = loss_risk + loss_bmi\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def test_epoch(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_risk = 0\n",
    "    correct_bmi = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            struct_feat = batch.struct_feat.to(device)\n",
    "            gene_data = batch.gene_data.to(device)\n",
    "            batch_vector = batch.batch.to(device)\n",
    "            out_risk, out_bmi = model(struct_feat, gene_data, batch_vector)\n",
    "            loss_risk = criterion(out_risk, batch.y_risk.to(device))\n",
    "            loss_bmi = criterion(out_bmi, batch.y_bmi.to(device))\n",
    "            loss = loss_risk + loss_bmi\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "            \n",
    "            pred_risk = out_risk.argmax(dim=1)\n",
    "            pred_bmi = out_bmi.argmax(dim=1)\n",
    "            correct_risk += (pred_risk == batch.y_risk.to(device)).sum().item()\n",
    "            correct_bmi += (pred_bmi == batch.y_bmi.to(device)).sum().item()\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc_risk = correct_risk / len(loader.dataset)\n",
    "    acc_bmi = correct_bmi / len(loader.dataset)\n",
    "    return avg_loss, acc_risk, acc_bmi\n",
    "\n",
    "#############################\n",
    "# Training Loop\n",
    "#############################\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader)\n",
    "    test_loss, test_acc_risk, test_acc_bmi = test_epoch(model, test_loader)\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch}: Train Loss {train_loss:.4f} | Test Loss {test_loss:.4f} | \"\n",
    "              f\"Risk Acc {test_acc_risk:.4f} | BMI Acc {test_acc_bmi:.4f}\")\n",
    "\n",
    "#############################\n",
    "# Save the Integrated Model and Artifacts\n",
    "#############################\n",
    "save_dir = r\"C:\\Users\\trejan\\Desktop\\GNN\\Saved models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(save_dir, \"integrated_model.pt\"))\n",
    "\n",
    "with open(os.path.join(save_dir, \"label_encoders.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "with open(os.path.join(save_dir, \"target_encoders.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({'risk': target_le_risk, 'bmi': target_le_bmi}, f)\n",
    "with open(os.path.join(save_dir, \"scaler.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Integrated model and preprocessing artifacts saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
