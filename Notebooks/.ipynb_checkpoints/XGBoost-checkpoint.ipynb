{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb22f415-a819-4046-b871-3ac0bded9d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7}\n",
      "Validation Accuracy (XGBoost): 100.00%\n",
      "Test Accuracy (XGBoost): 100.00%\n",
      "Cross-Validation Accuracy on Noisy Data (XGBoost): 84.29%\n",
      "\n",
      "Classification Report (Test Set - XGBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      1.00      1.00       194\n",
      "         Low       1.00      1.00      1.00       202\n",
      "      Medium       1.00      1.00      1.00       167\n",
      "\n",
      "    accuracy                           1.00       563\n",
      "   macro avg       1.00      1.00      1.00       563\n",
      "weighted avg       1.00      1.00      1.00       563\n",
      "\n",
      "\n",
      "Confusion Matrix (Test Set - XGBoost):\n",
      "[[194   0   0]\n",
      " [  0 202   0]\n",
      " [  0   0 167]]\n",
      "\n",
      "Predicted Obesity Risk Category: Medium\n",
      "\n",
      "=== Recommended Meals for Medium-Risk ===\n",
      "Total Meals in Cluster: 3637\n",
      "\n",
      "Top 5 Meals:\n",
      "Meal Description                                   Energy (kcal)   Protein (g)     Fat (g)         Carbs (g)      \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Snacks, popcorn, oil-popped, microwave, regular flavor, no trans fat 583.0           7.29            43.55           45.06          \n",
      "Chocolate, dark, 60-69% cacao solids               579.0           6.12            38.31           52.42          \n",
      "Candies, HERSHEY'S POT OF GOLD Almond Bar          577.0           12.82           38.46           46.15          \n",
      "Candies, MARS SNACKFOOD US, COCOAVIA Chocolate Covered Almonds 573.0           9.51            37.07           50.22          \n",
      "Candies, HERSHEY'S MILK CHOCOLATE WITH ALMOND BITES 568.0           9.76            35.73           51.72          \n",
      "\n",
      "=== Nutritional Summary ===\n",
      "Average Energy (kcal): 146.01\n",
      "Average Protein (g): 7.73\n",
      "Average Fat (g): 5.88\n",
      "Average Carbs (g): 15.77\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# -----------------------------\n",
    "# Load datasets\n",
    "# -----------------------------\n",
    "genetic_df = pd.read_csv(\"C:\\\\Users\\\\trejan\\\\Desktop\\\\Sem 2\\\\Machine Learning\\\\model\\\\new_genetic_profiles.csv\")\n",
    "meal_df = pd.read_csv(\"C:\\\\Users\\\\trejan\\\\Desktop\\\\Sem 2\\\\Machine Learning\\\\model\\\\train.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# Preprocess genetic data\n",
    "# -----------------------------\n",
    "# Handle missing values for numeric columns in genetic_df\n",
    "numeric_cols = genetic_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "genetic_df[numeric_cols] = genetic_df[numeric_cols].fillna(genetic_df[numeric_cols].mean())\n",
    "\n",
    "# Handle missing values for categorical columns in genetic_df\n",
    "categorical_cols = genetic_df.select_dtypes(include=['object']).columns\n",
    "genetic_df[categorical_cols] = genetic_df[categorical_cols].fillna('Unknown')\n",
    "\n",
    "# Convert Obesity_Risk_Score into categories (Low, Medium, High)\n",
    "genetic_df['Obesity_Risk_Category'] = pd.cut(\n",
    "    genetic_df['Obesity_Risk_Score'],\n",
    "    bins=[0, 0.3, 0.6, 1],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "# Select relevant features\n",
    "features = ['BMI', 'Physical_Activity', 'Diet_Type', 'MC4R_Variant', \n",
    "            'PPARG_Variant', 'FTO_Variant', 'LEPR_Variant', 'Obesity_Risk_Score']\n",
    "genetic_df = genetic_df[features + ['Obesity_Risk_Category']]\n",
    "\n",
    "# One-hot encode categorical features (Diet_Type and genetic variants)\n",
    "genetic_df = pd.get_dummies(genetic_df, columns=['Diet_Type', 'MC4R_Variant', \n",
    "                                                 'PPARG_Variant', 'FTO_Variant', 'LEPR_Variant'], drop_first=True)\n",
    "\n",
    "# Prepare features and target\n",
    "X = genetic_df.drop(['Obesity_Risk_Category'], axis=1)\n",
    "y = genetic_df['Obesity_Risk_Category']\n",
    "\n",
    "# Convert Obesity_Risk_Category to numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Ensure all columns in X are numeric\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')  # Convert to numeric, coercing errors to NaN\n",
    "        X[col] = X[col].fillna(0)  # Fill NaN values with 0\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "\n",
    "# Split resampled data into training (60%), validation (20%), and test (20%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# -----------------------------\n",
    "# Hyperparameter tuning with XGBoost\n",
    "# -----------------------------\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# Initialize XGBClassifier\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Grid Search CV for XGBoost\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid_xgb, cv=5, scoring='accuracy')\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "print(f'Best Parameters for XGBoost: {best_params_xgb}')\n",
    "\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation of XGBoost model\n",
    "# -----------------------------\n",
    "# Evaluate on the validation set\n",
    "y_val_pred_xgb = best_xgb.predict(X_val)\n",
    "val_accuracy_xgb = accuracy_score(y_val, y_val_pred_xgb) * 100\n",
    "print(f'Validation Accuracy (XGBoost): {val_accuracy_xgb:.2f}%')\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred_xgb = best_xgb.predict(X_test)\n",
    "test_accuracy_xgb = accuracy_score(y_test, y_test_pred_xgb) * 100\n",
    "print(f'Test Accuracy (XGBoost): {test_accuracy_xgb:.2f}%')\n",
    "\n",
    "# Evaluate on noisy data (optional)\n",
    "X_noisy = X_resampled + np.random.normal(0, 0.1, X_resampled.shape)  # Add Gaussian noise\n",
    "cv_scores_noisy_xgb = cross_val_score(best_xgb, X_noisy, y_resampled, cv=5, scoring='accuracy')\n",
    "print(f'Cross-Validation Accuracy on Noisy Data (XGBoost): {cv_scores_noisy_xgb.mean() * 100:.2f}%')\n",
    "\n",
    "# Print classification report and confusion matrix for the test set\n",
    "print(\"\\nClassification Report (Test Set - XGBoost):\")\n",
    "print(classification_report(y_test, y_test_pred_xgb, target_names=label_encoder.classes_))\n",
    "\n",
    "print(\"\\nConfusion Matrix (Test Set - XGBoost):\")\n",
    "print(confusion_matrix(y_test, y_test_pred_xgb))\n",
    "\n",
    "# -----------------------------\n",
    "# Preprocess nutritional data for meal recommendations\n",
    "# -----------------------------\n",
    "nutritional_features = meal_df[['Energy_kcal', 'Protein_g', 'Fat_g', 'Carb_g']]\n",
    "scaler = StandardScaler()\n",
    "nutritional_features_scaled = scaler.fit_transform(nutritional_features)\n",
    "\n",
    "# Increase the number of meal clusters\n",
    "num_clusters = 10  # Using 10 clusters for more diversity\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "meal_df['Meal_Cluster'] = kmeans.fit_predict(nutritional_features_scaled)\n",
    "\n",
    "# -----------------------------\n",
    "# Functions for Meal Recommendations\n",
    "# -----------------------------\n",
    "def display_meal_cluster(meals, cluster_name, num_meals=5):\n",
    "    print(f\"\\n=== Recommended Meals for {cluster_name} ===\")\n",
    "    print(f\"Total Meals in Cluster: {len(meals)}\")\n",
    "    \n",
    "    # Display a subset of meals\n",
    "    print(f\"\\nTop {num_meals} Meals:\")\n",
    "    print(f\"{'Meal Description':<50} {'Energy (kcal)':<15} {'Protein (g)':<15} {'Fat (g)':<15} {'Carbs (g)':<15}\")\n",
    "    print(\"-\" * 110)\n",
    "    for _, meal in meals.head(num_meals).iterrows():\n",
    "        print(f\"{meal['Descrip']:<50} {meal['Energy_kcal']:<15} {meal['Protein_g']:<15} {meal['Fat_g']:<15} {meal['Carb_g']:<15}\")\n",
    "    \n",
    "    # Display summary of nutritional values\n",
    "    avg_energy = meals['Energy_kcal'].mean()\n",
    "    avg_protein = meals['Protein_g'].mean()\n",
    "    avg_fat = meals['Fat_g'].mean()\n",
    "    avg_carbs = meals['Carb_g'].mean()\n",
    "    \n",
    "    print(\"\\n=== Nutritional Summary ===\")\n",
    "    print(f\"Average Energy (kcal): {avg_energy:.2f}\")\n",
    "    print(f\"Average Protein (g): {avg_protein:.2f}\")\n",
    "    print(f\"Average Fat (g): {avg_fat:.2f}\")\n",
    "    print(f\"Average Carbs (g): {avg_carbs:.2f}\")\n",
    "\n",
    "def recommend_meals(user_profile, meal_df, model, label_encoder, num_meals=5):\n",
    "    # Convert the user profile to a DataFrame\n",
    "    user_profile_df = pd.DataFrame([user_profile])\n",
    "    \n",
    "    # One-hot encode categorical features (same as during training)\n",
    "    user_profile_df = pd.get_dummies(user_profile_df, columns=['Diet_Type', 'MC4R_Variant', \n",
    "                                                               'PPARG_Variant', 'FTO_Variant', 'LEPR_Variant'], drop_first=True)\n",
    "    \n",
    "    # Ensure the user profile has the same columns as the training data\n",
    "    missing_cols = set(X_train.columns) - set(user_profile_df.columns)\n",
    "    for col in missing_cols:\n",
    "        user_profile_df[col] = 0  # Add missing columns with default value 0\n",
    "    \n",
    "    # Reorder columns to match the training data\n",
    "    user_profile_df = user_profile_df[X_train.columns]\n",
    "    \n",
    "    # Predict the obesity risk category for the user profile\n",
    "    predicted_risk_category = model.predict(user_profile_df)\n",
    "    predicted_risk_category_label = label_encoder.inverse_transform(predicted_risk_category)[0]\n",
    "    print(f'\\nPredicted Obesity Risk Category: {predicted_risk_category_label}')\n",
    "    \n",
    "    # Define cluster preferences based on risk category\n",
    "    if predicted_risk_category_label == 'Low':\n",
    "        # Low-risk users: Focus on high-protein, balanced meals\n",
    "        preferred_clusters = [0, 1, 2]  # Example clusters\n",
    "        sort_by = 'Protein_g'  # Sort by highest protein\n",
    "    elif predicted_risk_category_label == 'Medium':\n",
    "        # Medium-risk users: Focus on moderate-calorie, balanced meals\n",
    "        preferred_clusters = [3, 4, 5]  # Example clusters\n",
    "        sort_by = 'Energy_kcal'  # Sort by moderate calories\n",
    "    else:\n",
    "        # High-risk users: Focus on low-calorie, nutrient-dense meals\n",
    "        preferred_clusters = [6, 7, 8, 9]  # Example clusters\n",
    "        sort_by = 'Energy_kcal'  # Sort by lowest calories\n",
    "    \n",
    "    # Recommend meals from the preferred clusters\n",
    "    recommended_meals = meal_df[meal_df['Meal_Cluster'].isin(preferred_clusters)]\n",
    "    \n",
    "    # Sort meals based on the user's risk category\n",
    "    if predicted_risk_category_label == 'High':\n",
    "        recommended_meals = recommended_meals.sort_values(by=sort_by, ascending=True)  # Low calories\n",
    "    else:\n",
    "        recommended_meals = recommended_meals.sort_values(by=sort_by, ascending=False)  # High protein or moderate calories\n",
    "    \n",
    "    # Display recommended meals in a user-friendly format\n",
    "    display_meal_cluster(recommended_meals, f\"{predicted_risk_category_label}-Risk\", num_meals)\n",
    "\n",
    "# -----------------------------\n",
    "# Example: Recommend Meals for a New Genetic Profile\n",
    "# -----------------------------\n",
    "new_profile = {\n",
    "    'BMI': 28.5,                 # Example value\n",
    "    'Physical_Activity': 2,      # Example value (1: Low, 2: Moderate, 3: High)\n",
    "    'Diet_Type': 'High-Fat',     # Example value\n",
    "    'MC4R_Variant': 'rs17782313_CT',  # Example value\n",
    "    'PPARG_Variant': 'rs1801282_CG',   # Example value\n",
    "    'FTO_Variant': 'rs9939609_AT',      # Example value\n",
    "    'LEPR_Variant': 'rs1137101_AG',      # Example value\n",
    "    'Obesity_Risk_Score': 0.45   # Example value\n",
    "}\n",
    "\n",
    "# Use best_xgb for prediction and meal recommendation\n",
    "recommend_meals(new_profile, meal_df, best_xgb, label_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf75ede4-d8e1-4edd-8c52-a21e4ffa1bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:21:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:22:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:22:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:22:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:22:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:22:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:22:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:22:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:22:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:22:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:22:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:22:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:22:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\trejan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:22:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 83\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Grid Search CV for XGBoost\u001b[39;00m\n\u001b[0;32m     82\u001b[0m grid_search_xgb \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgb, param_grid\u001b[38;5;241m=\u001b[39mparam_grid_xgb, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 83\u001b[0m \u001b[43mgrid_search_xgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Get the best parameters and best estimator\u001b[39;00m\n\u001b[0;32m     86\u001b[0m best_params_xgb \u001b[38;5;241m=\u001b[39m grid_search_xgb\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 866\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\sklearn.py:1599\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1579\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1580\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1581\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1582\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1596\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1597\u001b[0m )\n\u001b[1;32m-> 1599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1602\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib  # Added for saving models\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# Load datasets\n",
    "# -----------------------------\n",
    "genetic_df = pd.read_csv(\"C:\\\\Users\\\\trejan\\\\Desktop\\\\Sem 2\\\\Machine Learning\\\\model\\\\new_genetic_profiles.csv\")\n",
    "meal_df = pd.read_csv(\"C:\\\\Users\\\\trejan\\\\Desktop\\\\Sem 2\\\\Machine Learning\\\\model\\\\train.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# Preprocess genetic data\n",
    "# -----------------------------\n",
    "# Handle missing values for numeric columns in genetic_df\n",
    "numeric_cols = genetic_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "genetic_df[numeric_cols] = genetic_df[numeric_cols].fillna(genetic_df[numeric_cols].mean())\n",
    "\n",
    "# Handle missing values for categorical columns in genetic_df\n",
    "categorical_cols = genetic_df.select_dtypes(include=['object']).columns\n",
    "genetic_df[categorical_cols] = genetic_df[categorical_cols].fillna('Unknown')\n",
    "\n",
    "# Convert Obesity_Risk_Score into categories (Low, Medium, High)\n",
    "genetic_df['Obesity_Risk_Category'] = pd.cut(\n",
    "    genetic_df['Obesity_Risk_Score'],\n",
    "    bins=[0, 0.3, 0.6, 1],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "# Select relevant features\n",
    "features = ['BMI', 'Physical_Activity', 'Diet_Type', 'MC4R_Variant', \n",
    "            'PPARG_Variant', 'FTO_Variant', 'LEPR_Variant', 'Obesity_Risk_Score']\n",
    "genetic_df = genetic_df[features + ['Obesity_Risk_Category']]\n",
    "\n",
    "# One-hot encode categorical features (Diet_Type and genetic variants)\n",
    "genetic_df = pd.get_dummies(genetic_df, columns=['Diet_Type', 'MC4R_Variant', \n",
    "                                                 'PPARG_Variant', 'FTO_Variant', 'LEPR_Variant'], drop_first=True)\n",
    "\n",
    "# Prepare features and target\n",
    "X = genetic_df.drop(['Obesity_Risk_Category'], axis=1)\n",
    "y = genetic_df['Obesity_Risk_Category']\n",
    "\n",
    "# Convert Obesity_Risk_Category to numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Ensure all columns in X are numeric\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')  # Convert to numeric, coercing errors to NaN\n",
    "        X[col] = X[col].fillna(0)  # Fill NaN values with 0\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "\n",
    "# Split resampled data into training (60%), validation (20%), and test (20%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# -----------------------------\n",
    "# Hyperparameter tuning with XGBoost\n",
    "# -----------------------------\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# Initialize XGBClassifier\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Grid Search CV for XGBoost\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid_xgb, cv=5, scoring='accuracy')\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "print(f'Best Parameters for XGBoost: {best_params_xgb}')\n",
    "\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# Save the XGBoost model and preprocessing artifacts\n",
    "# -----------------------------\n",
    "save_dir = r\"C:\\Users\\trejan\\Desktop\\GNN\\Saved models\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "# Save the model and preprocessing objects\n",
    "joblib.dump(best_xgb, os.path.join(save_dir, \"xgboost_model.pkl\"))  # Save the XGBoost model\n",
    "joblib.dump(label_encoder, os.path.join(save_dir, \"xgboost_label_encoder.pkl\"))  # Save the label encoder\n",
    "joblib.dump(smote, os.path.join(save_dir, \"xgboost_smote.pkl\"))  # Save the SMOTE object\n",
    "joblib.dump(X_train.columns, os.path.join(save_dir, \"xgboost_feature_columns.pkl\"))  # Save the feature columns\n",
    "\n",
    "print(f\"\\nXGBoost model and preprocessing artifacts saved to: {save_dir}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation of XGBoost model\n",
    "# -----------------------------\n",
    "# Evaluate on the validation set\n",
    "y_val_pred_xgb = best_xgb.predict(X_val)\n",
    "val_accuracy_xgb = accuracy_score(y_val, y_val_pred_xgb) * 100\n",
    "print(f'Validation Accuracy (XGBoost): {val_accuracy_xgb:.2f}%')\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred_xgb = best_xgb.predict(X_test)\n",
    "test_accuracy_xgb = accuracy_score(y_test, y_test_pred_xgb) * 100\n",
    "print(f'Test Accuracy (XGBoost): {test_accuracy_xgb:.2f}%')\n",
    "\n",
    "# Evaluate on noisy data (optional)\n",
    "X_noisy = X_resampled + np.random.normal(0, 0.1, X_resampled.shape)  # Add Gaussian noise\n",
    "cv_scores_noisy_xgb = cross_val_score(best_xgb, X_noisy, y_resampled, cv=5, scoring='accuracy')\n",
    "print(f'Cross-Validation Accuracy on Noisy Data (XGBoost): {cv_scores_noisy_xgb.mean() * 100:.2f}%')\n",
    "\n",
    "# Print classification report and confusion matrix for the test set\n",
    "print(\"\\nClassification Report (Test Set - XGBoost):\")\n",
    "print(classification_report(y_test, y_test_pred_xgb, target_names=label_encoder.classes_))\n",
    "\n",
    "print(\"\\nConfusion Matrix (Test Set - XGBoost):\")\n",
    "print(confusion_matrix(y_test, y_test_pred_xgb))\n",
    "\n",
    "# -----------------------------\n",
    "# Preprocess nutritional data for meal recommendations\n",
    "# -----------------------------\n",
    "nutritional_features = meal_df[['Energy_kcal', 'Protein_g', 'Fat_g', 'Carb_g']]\n",
    "scaler = StandardScaler()\n",
    "nutritional_features_scaled = scaler.fit_transform(nutritional_features)\n",
    "\n",
    "# Increase the number of meal clusters\n",
    "num_clusters = 10  # Using 10 clusters for more diversity\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "meal_df['Meal_Cluster'] = kmeans.fit_predict(nutritional_features_scaled)\n",
    "\n",
    "# -----------------------------\n",
    "# Functions for Meal Recommendations\n",
    "# -----------------------------\n",
    "def display_meal_cluster(meals, cluster_name, num_meals=5):\n",
    "    print(f\"\\n=== Recommended Meals for {cluster_name} ===\")\n",
    "    print(f\"Total Meals in Cluster: {len(meals)}\")\n",
    "    \n",
    "    # Display a subset of meals\n",
    "    print(f\"\\nTop {num_meals} Meals:\")\n",
    "    print(f\"{'Meal Description':<50} {'Energy (kcal)':<15} {'Protein (g)':<15} {'Fat (g)':<15} {'Carbs (g)':<15}\")\n",
    "    print(\"-\" * 110)\n",
    "    for _, meal in meals.head(num_meals).iterrows():\n",
    "        print(f\"{meal['Descrip']:<50} {meal['Energy_kcal']:<15} {meal['Protein_g']:<15} {meal['Fat_g']:<15} {meal['Carb_g']:<15}\")\n",
    "    \n",
    "    # Display summary of nutritional values\n",
    "    avg_energy = meals['Energy_kcal'].mean()\n",
    "    avg_protein = meals['Protein_g'].mean()\n",
    "    avg_fat = meals['Fat_g'].mean()\n",
    "    avg_carbs = meals['Carb_g'].mean()\n",
    "    \n",
    "    print(\"\\n=== Nutritional Summary ===\")\n",
    "    print(f\"Average Energy (kcal): {avg_energy:.2f}\")\n",
    "    print(f\"Average Protein (g): {avg_protein:.2f}\")\n",
    "    print(f\"Average Fat (g): {avg_fat:.2f}\")\n",
    "    print(f\"Average Carbs (g): {avg_carbs:.2f}\")\n",
    "\n",
    "def recommend_meals(user_profile, meal_df, model, label_encoder, num_meals=5):\n",
    "    # Convert the user profile to a DataFrame\n",
    "    user_profile_df = pd.DataFrame([user_profile])\n",
    "    \n",
    "    # One-hot encode categorical features (same as during training)\n",
    "    user_profile_df = pd.get_dummies(user_profile_df, columns=['Diet_Type', 'MC4R_Variant', \n",
    "                                                               'PPARG_Variant', 'FTO_Variant', 'LEPR_Variant'], drop_first=True)\n",
    "    \n",
    "    # Ensure the user profile has the same columns as the training data\n",
    "    missing_cols = set(X_train.columns) - set(user_profile_df.columns)\n",
    "    for col in missing_cols:\n",
    "        user_profile_df[col] = 0  # Add missing columns with default value 0\n",
    "    \n",
    "    # Reorder columns to match the training data\n",
    "    user_profile_df = user_profile_df[X_train.columns]\n",
    "    \n",
    "    # Predict the obesity risk category for the user profile\n",
    "    predicted_risk_category = model.predict(user_profile_df)\n",
    "    predicted_risk_category_label = label_encoder.inverse_transform(predicted_risk_category)[0]\n",
    "    print(f'\\nPredicted Obesity Risk Category: {predicted_risk_category_label}')\n",
    "    \n",
    "    # Define cluster preferences based on risk category\n",
    "    if predicted_risk_category_label == 'Low':\n",
    "        # Low-risk users: Focus on high-protein, balanced meals\n",
    "        preferred_clusters = [0, 1, 2]  # Example clusters\n",
    "        sort_by = 'Protein_g'  # Sort by highest protein\n",
    "    elif predicted_risk_category_label == 'Medium':\n",
    "        # Medium-risk users: Focus on moderate-calorie, balanced meals\n",
    "        preferred_clusters = [3, 4, 5]  # Example clusters\n",
    "        sort_by = 'Energy_kcal'  # Sort by moderate calories\n",
    "    else:\n",
    "        # High-risk users: Focus on low-calorie, nutrient-dense meals\n",
    "        preferred_clusters = [6, 7, 8, 9]  # Example clusters\n",
    "        sort_by = 'Energy_kcal'  # Sort by lowest calories\n",
    "    \n",
    "    # Recommend meals from the preferred clusters\n",
    "    recommended_meals = meal_df[meal_df['Meal_Cluster'].isin(preferred_clusters)]\n",
    "    \n",
    "    # Sort meals based on the user's risk category\n",
    "    if predicted_risk_category_label == 'High':\n",
    "        recommended_meals = recommended_meals.sort_values(by=sort_by, ascending=True)  # Low calories\n",
    "    else:\n",
    "        recommended_meals = recommended_meals.sort_values(by=sort_by, ascending=False)  # High protein or moderate calories\n",
    "    \n",
    "    # Display recommended meals in a user-friendly format\n",
    "    display_meal_cluster(recommended_meals, f\"{predicted_risk_category_label}-Risk\", num_meals)\n",
    "\n",
    "# -----------------------------\n",
    "# Example: Recommend Meals for a New Genetic Profile\n",
    "# -----------------------------\n",
    "new_profile = {\n",
    "    'BMI': 28.5,                 # Example value\n",
    "    'Physical_Activity': 2,      # Example value (1: Low, 2: Moderate, 3: High)\n",
    "    'Diet_Type': 'High-Fat',     # Example value\n",
    "    'MC4R_Variant': 'rs17782313_CT',  # Example value\n",
    "    'PPARG_Variant': 'rs1801282_CG',   # Example value\n",
    "    'FTO_Variant': 'rs9939609_AT',      # Example value\n",
    "    'LEPR_Variant': 'rs1137101_AG',      # Example value\n",
    "    'Obesity_Risk_Score': 0.45   # Example value\n",
    "}\n",
    "\n",
    "# Use best_xgb for prediction and meal recommendation\n",
    "recommend_meals(new_profile, meal_df, best_xgb, label_encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
